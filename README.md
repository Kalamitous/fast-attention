# fast-attention
 A CUDA implementation of attention with kernel-level optimizations.
